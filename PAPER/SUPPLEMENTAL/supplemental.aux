\relax 
\providecommand \oddpage@label [2]{}
\bibstyle{abbrv-doi}
\bibdata{../paper.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Error distributions.} Error distributions of our networks when decoding elementary perceptual tasks.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:errors}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Cross-network variability.} Our networks fail when the stimuli changes through translation or stroke width. The x-labels indicate the training configuration while the y-labels indicate the stimuli variation. Numbers represent MLAE.\relax }}{4}}
\newlabel{fig:cross_network}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Elementary perceptual tasks.} Midmean logistic absolute errors (MLAE) for all generated stimuli and across all networks. The * indicates networks which use ImageNet weights instead of bein trained from scratch.\relax }}{5}}
\newlabel{fig:cross_network}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Elementary perceptual tasks.} Midmean logistic absolute errors (MLAE) visualized as box plots.\relax }}{6}}
\newlabel{fig:cross_network}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Anti-aliasing.} We test whether anti-aliasing effects the performance of our networks on pie charts by measuring MLAE. The difference is not statistically significant ($F(1,30)=0.341,p>0.5$).\relax }}{7}}
\newlabel{fig:aa}{{5}{7}}
