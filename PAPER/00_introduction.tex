\firstsection{Introduction}

\maketitle

Convolutional neural networks (CNNs) have been successfully applied to a wide range of visual tasks, most famously to natural image object recognition~\cite{krizhevsky_imagenet2012, simonyan_very_deep2014, szegedy2015}, for which some claim equivalent or better than human performance. This performance comparison is often motivated by the idea that CNNs model or reproduce the early layers of the visual cortex, even though they do not incorporate many details of biological neural networks or model higher-level abstract or symbolic reasoning~\cite{yamins2016using, hassabis2017neuroscience, human_vs_machine_vision}. While CNN techniques were originally inspired by neuroscientific discoveries, recent advances in processing larger datasets with deeper networks have been the direct results of engineering efforts. Throughout this significant advancement, researchers have aimed to understand why and how CNNs produce such high performance~\cite{goodfellow_book, deeplearning_blackbox2017}, with recent works targetting the systematic evaluation of the visual perception limits of CNNs~\cite{clevr, not_so_clevr}.

One fundamental application of human vision is in understanding data visualizations. This is a task unlike processing natural images, where real-world objects and their effects are abstracted into data and represented with visual marks. As a field, visualization catalogues and evaluates human perception of these figures, such as in the seminal \emph{graphical perception} experiments of Cleveland and McGill~\cite{cleveland_mcgill}. This work describes nine elementary perceptual reasoning tasks, such as position relative to a scale, length, angle, area, and shading density, plus orders their reasoning difficulty. But, with more research interested in the machine analysis of graphs, charts, and visual encodings, it seems pertinent to question whether CNNs are able to process these basic graphical elements, and derive useful measurements from the building blocks of information visualization.

As such, we explore whether these experiments which were performed with humans can be reproduced with CNNs. Cleveland and McGill's work in the 1980s has led to many insights for modern information visualization research such as the identification of elementary perceptional tasks or that bar charts are easier to understand than pie charts. 

In order to perform this evaluation, we parametrize different visual encodings such as the elementary perceptual tasks suggested by Cleveland and McGill~\cite{cleveland_mcgill}. We then replicate the original experimental design by defining linear regression tasks for continuous variables. However, we select three modern feature generators based on convolutional neural networks and combine them with a multilayer perceptron (MLP) to include non-linearities. We include the LeNet-5 network~\cite{lenet}, the VGG19 network~\cite{simonyan_very_deep2014}, and the Xception classifiers~\cite{xception}. While we train LeNet-5 from scratch, for VGG19 and Xception we use pre-trained imagenet~\cite{imagenet} weights to further mimic the human visual system. By also using the MLP directly without convolutional feature detection as baseline, we test four different classifiers as part of the following scenarios: a) elementary perceptual tasks with increasing parameteric complexity, b) position-angle experiment comparing pie charts to bar charts, c) position-length experiment that compares grouped and divided bar charts, and d) the bars and framed rectangles experiments where visual cues aid perception. We also investigate other properties of CNNs such as whether they obey Weber's law which defines a proportional dependency between an initial distribution and perceivable change. Our experimental setup includes repetitions, randomizations, and regularizations to prevent any bias. 

Our motivation for replicating Cleveland and McGill's experiments stems from the thought that computational perception seems to be closely related to biological vision. If human perception yields certain results, maybe we can replicate these results with machine vision. As our first contribution, we study the elementary perceptual tasks by Cleveland and McGill and then systematically parametrize and evaluate them for computational perception with our four classifiers. This setup includes also cross-network evaluations which give insight into the generalizability of the classifiers. It also yields our second contribution: a ranking of Cleveland and McGill's elementary perceptual tasks for our tested CNN architectures. Further, we replicate the \emph{position-angle} and the \emph{position-length} experiments which contributes to the general knowledge of superior perceivability of bar charts to pie charts in certain conditions. We then reproduce the \emph{bars-and-framed-rectangles} experiment with our classifiers. Here, we also include an additional experiment to test the Weber-Fechner's law for CNNs. Our experiments yield a TODO. Finally, we discuss our findings and derive recommendations for allowing CNNs to perceive visualizations.

We accompany this paper and detailed supplemental material with open source code~\footnote{Code, data, results and more are available at: \url{http://rhoana.org/perception}}, data, and results to enable a framework for the development and evaluation of new network architectures for graphical perception.


%\emph{Can we leverage decades of visualization research to understand the way convolutional neural networks process data?}
%
%Information visualization has been an established research field for decades which has resulted in numerous insightful findings in regards to how human beings can best process information visually.
%Unpublished preliminary experiments have shown that data representations customized for the human eye also can improve the performance of an automatic classifier. 
%While the reasons for this are still unknown, specified research can most certainly advance the understanding of deep neural networks.
%
%\subsection{From Biological Vision to Machine Learning}
%
%%\begin{figure}[t]
%%	  \includegraphics[width=\linewidth]{biology_vs_cnn.png}
%%  \caption{The Biological Vision (schematic)}
%%	\label{fig:vision}
%%\end{figure}
%
%Biological vision is an extremely powerful system which allows humans the ability, and seemingly without effort, to recognize an enormous amount of distinct objects in the world. 
%Object detection is extremely difficult and therefore is especially impressive as light intensities can change by levels of magnitude and contrast between foreground and background is so often low. 
%In addition, the visual scene changes every time the human body or human eyes move. 
%This visual system exhibits a very noisy structure but because it is organized by layers it has inspired the mathematical theory of multilayer neural networks. 
%What is remarkable is that even though current machine learning models do not resemble the complexity of its biological pendant, they inherently generalize extremely well. 
%Neural networks trained on one specific task can be used to perform detection or segmentation of, seemingly, unrelated objects with relatively minor retraining. 
%The reported classification performance is superior to that of humans and the question in regards to their functionality opens an interesting research topic.
%
%In 1962 Hubel and Wiesel were the first to begin studying the visual cortex from the standpoint of a neuroscientist. Their experimental findings on cats and macaque monkeys suggested a hierarchy of cells with increasing complexity which was then later transferred to the hierarchical model of different layers. Twenty years later, this insight was translated to the Neocognitron quantitative model, by Fukushima and Miyake, which ultimately led to the important work of Hinton, Bengio, and LeCun in the 1980s. Their work on stochastic gradient descent approximation, and the availability of faster computer hardware then led to todayâ€™s breakthrough of deep learning networks. In the last decade, this field has exhibited rapid growth, constant evolution, and new applications in various domains.
%
%We think that the biological inspiration of modern convolutional neural networks yields the evaluation of principles of human perception with computers.
%

