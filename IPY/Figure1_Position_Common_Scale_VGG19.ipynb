{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ClevelandMcGill' from '../EXP/ClevelandMcGill/__init__.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import cPickle as pickle\n",
    "sys.path.append('../EXP/')\n",
    "import ClevelandMcGill as C\n",
    "reload(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "images = np.zeros((N,100,100), dtype=np.bool)\n",
    "labels = np.zeros((N), dtype=np.float32)\n",
    "\n",
    "for n in range(N):\n",
    "  \n",
    "  sparse, image, label, parameters = C.Figure1.position_common_scale()\n",
    "  \n",
    "  images[n] = image\n",
    "  labels[n] = label\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage 4000.4 MB\n"
     ]
    }
   ],
   "source": [
    "X = images.astype(np.float32) - .5\n",
    "y = (labels-np.min(labels))/(np.max(labels)-np.min(labels))\n",
    "print 'memory usage', (X.nbytes + y.nbytes) / 1000000., 'MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage 12000.4 MB\n"
     ]
    }
   ],
   "source": [
    "X3D = np.stack((X,)*3, -1)\n",
    "print 'memory usage', (X3D.nbytes + y.nbytes) / 1000000., 'MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 276s 3ms/step\n",
      "VGG19 features done after 275.932182789\n"
     ]
    }
   ],
   "source": [
    "import keras.applications\n",
    "\n",
    "VGG19 = keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(100,100,3))\n",
    "\n",
    "t0 = time.time()\n",
    "features = VGG19.predict(X3D, verbose=True)\n",
    "print 'VGG19 features done after', time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape (100000, 3, 3, 512)\n",
      "memory usage 1843.6 MB\n"
     ]
    }
   ],
   "source": [
    "oshape = features.shape\n",
    "print 'features shape', oshape\n",
    "print 'memory usage', (features.nbytes + y.nbytes) / 1000000., 'MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "MLP = models.Sequential()\n",
    "\n",
    "MLP.add(layers.Dense(256, activation='relu', input_dim=oshape[1]*oshape[2]*oshape[3]))\n",
    "MLP.add(layers.Dropout(0.5))\n",
    "MLP.add(layers.Dense(1, activation='linear')) # REGRESSION\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "MLP.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse', 'mae']) # MSE for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/1000\n",
      "45000/45000 [==============================] - 7s 153us/step - loss: 0.0275 - mean_squared_error: 0.0275 - mean_absolute_error: 0.1036 - val_loss: 9.8928e-04 - val_mean_squared_error: 9.8928e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 2/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0670 - val_loss: 6.3442e-04 - val_mean_squared_error: 6.3442e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 3/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0612 - val_loss: 3.6496e-04 - val_mean_squared_error: 3.6496e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 4/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0574 - val_loss: 5.1544e-04 - val_mean_squared_error: 5.1544e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 5/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0055 - mean_squared_error: 0.0055 - mean_absolute_error: 0.0549 - val_loss: 4.4304e-04 - val_mean_squared_error: 4.4304e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 6/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0050 - mean_squared_error: 0.0050 - mean_absolute_error: 0.0522 - val_loss: 3.8011e-04 - val_mean_squared_error: 3.8011e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 7/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0048 - mean_squared_error: 0.0048 - mean_absolute_error: 0.0506 - val_loss: 4.0318e-04 - val_mean_squared_error: 4.0318e-04 - val_mean_absolute_error: 0.0159\n",
      "Epoch 8/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0487 - val_loss: 4.5014e-04 - val_mean_squared_error: 4.5014e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 9/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0474 - val_loss: 1.5766e-04 - val_mean_squared_error: 1.5766e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 10/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0461 - val_loss: 1.4117e-04 - val_mean_squared_error: 1.4117e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 11/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0447 - val_loss: 3.9462e-04 - val_mean_squared_error: 3.9462e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 12/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0437 - val_loss: 1.1851e-04 - val_mean_squared_error: 1.1851e-04 - val_mean_absolute_error: 0.0087\n",
      "Epoch 13/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0035 - mean_squared_error: 0.0035 - mean_absolute_error: 0.0427 - val_loss: 7.8548e-05 - val_mean_squared_error: 7.8548e-05 - val_mean_absolute_error: 0.0071\n",
      "Epoch 14/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0034 - mean_squared_error: 0.0034 - mean_absolute_error: 0.0417 - val_loss: 1.3609e-04 - val_mean_squared_error: 1.3609e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 15/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0032 - mean_squared_error: 0.0032 - mean_absolute_error: 0.0407 - val_loss: 1.3126e-04 - val_mean_squared_error: 1.3126e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 16/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0032 - mean_squared_error: 0.0032 - mean_absolute_error: 0.0403 - val_loss: 1.0454e-04 - val_mean_squared_error: 1.0454e-04 - val_mean_absolute_error: 0.0085\n",
      "Epoch 17/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0031 - mean_squared_error: 0.0031 - mean_absolute_error: 0.0396 - val_loss: 5.9169e-05 - val_mean_squared_error: 5.9169e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 18/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0030 - mean_squared_error: 0.0030 - mean_absolute_error: 0.0393 - val_loss: 7.3565e-05 - val_mean_squared_error: 7.3565e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 19/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0029 - mean_squared_error: 0.0029 - mean_absolute_error: 0.0387 - val_loss: 7.3787e-05 - val_mean_squared_error: 7.3787e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 20/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0029 - mean_squared_error: 0.0029 - mean_absolute_error: 0.0382 - val_loss: 8.3433e-05 - val_mean_squared_error: 8.3433e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 21/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0377 - val_loss: 1.2979e-04 - val_mean_squared_error: 1.2979e-04 - val_mean_absolute_error: 0.0092\n",
      "Epoch 22/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0376 - val_loss: 1.6321e-04 - val_mean_squared_error: 1.6321e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 23/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0369 - val_loss: 5.9521e-05 - val_mean_squared_error: 5.9521e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 24/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0369 - val_loss: 1.5887e-04 - val_mean_squared_error: 1.5887e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 25/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0026 - mean_squared_error: 0.0026 - mean_absolute_error: 0.0367 - val_loss: 4.5031e-05 - val_mean_squared_error: 4.5031e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 26/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0026 - mean_squared_error: 0.0026 - mean_absolute_error: 0.0364 - val_loss: 7.7865e-05 - val_mean_squared_error: 7.7865e-05 - val_mean_absolute_error: 0.0071\n",
      "Epoch 27/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0360 - val_loss: 1.2661e-04 - val_mean_squared_error: 1.2661e-04 - val_mean_absolute_error: 0.0095\n",
      "Epoch 28/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0360 - val_loss: 7.3858e-05 - val_mean_squared_error: 7.3858e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 29/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0358 - val_loss: 2.6662e-04 - val_mean_squared_error: 2.6662e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 30/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0355 - val_loss: 6.8376e-05 - val_mean_squared_error: 6.8376e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 31/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0354 - val_loss: 9.6741e-05 - val_mean_squared_error: 9.6741e-05 - val_mean_absolute_error: 0.0084\n",
      "Epoch 32/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0353 - val_loss: 4.5675e-05 - val_mean_squared_error: 4.5675e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 33/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0352 - val_loss: 4.3447e-05 - val_mean_squared_error: 4.3447e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0352 - val_loss: 7.0385e-05 - val_mean_squared_error: 7.0385e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 35/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0349 - val_loss: 1.2575e-04 - val_mean_squared_error: 1.2575e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 36/1000\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0349 - val_loss: 1.1306e-04 - val_mean_squared_error: 1.1306e-04 - val_mean_absolute_error: 0.0092\n",
      "Epoch 37/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0350 - val_loss: 1.0607e-04 - val_mean_squared_error: 1.0607e-04 - val_mean_absolute_error: 0.0090\n",
      "Epoch 38/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0347 - val_loss: 8.6878e-05 - val_mean_squared_error: 8.6878e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 39/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0349 - val_loss: 1.2801e-04 - val_mean_squared_error: 1.2801e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 40/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0346 - val_loss: 1.8016e-04 - val_mean_squared_error: 1.8016e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 41/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0345 - val_loss: 1.6556e-04 - val_mean_squared_error: 1.6556e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 42/1000\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0349 - val_loss: 1.1141e-04 - val_mean_squared_error: 1.1141e-04 - val_mean_absolute_error: 0.0091\n",
      "Epoch 43/1000\n",
      "45000/45000 [==============================] - 7s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0344 - val_loss: 1.7342e-04 - val_mean_squared_error: 1.7342e-04 - val_mean_absolute_error: 0.0113\n",
      "Fitting done 284.899347067\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')]\n",
    "\n",
    "history = MLP.fit(features[0:60000].reshape(60000, oshape[1]*oshape[2]*oshape[3]), \\\n",
    "                  y[0:60000], \\\n",
    "                  epochs=1000, \\\n",
    "                  batch_size=32, \\\n",
    "                  validation_split=0.25,\n",
    "                  callbacks=callbacks,\n",
    "                  verbose=True)\n",
    "print 'Fitting done', time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = MLP.predict(features[60000:].reshape(40000, oshape[1]*oshape[2]*oshape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33803462683127294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "y_test = y[60000:]\n",
    "np.log2(sklearn.metrics.mean_absolute_error(y_pred*100, y_test*100)+.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
