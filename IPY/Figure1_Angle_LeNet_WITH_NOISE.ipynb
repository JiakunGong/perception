{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ClevelandMcGill' from '../EXP/ClevelandMcGill/__init__.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import cPickle as pickle\n",
    "sys.path.append('../EXP/')\n",
    "import ClevelandMcGill as C\n",
    "reload(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOISE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 110.705868006 seconds ( 566244 iterations)\n"
     ]
    }
   ],
   "source": [
    "train_target = 60000\n",
    "val_target = 20000\n",
    "test_target = 20000\n",
    "\n",
    "X_train = np.zeros((train_target, 100, 100), dtype=np.float32)\n",
    "y_train = np.zeros((train_target), dtype=np.float32)\n",
    "train_counter = 0\n",
    "\n",
    "X_val = np.zeros((val_target, 100, 100), dtype=np.float32)\n",
    "y_val = np.zeros((val_target), dtype=np.float32)\n",
    "val_counter = 0\n",
    "\n",
    "X_test = np.zeros((test_target, 100, 100), dtype=np.float32)\n",
    "y_test = np.zeros((test_target), dtype=np.float32)\n",
    "test_counter = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "all_counter = 0\n",
    "while train_counter < train_target or val_counter < val_target or test_counter < test_target:\n",
    "  \n",
    "  all_counter += 1\n",
    "  \n",
    "  sparse, image, label, parameters = C.Figure1.angle()\n",
    "  \n",
    "  if label == 0:\n",
    "    break\n",
    "  \n",
    "  # we need float\n",
    "  image = image.astype(np.float32)\n",
    "  \n",
    "  pot = np.random.choice(3, p=([.6,.2,.2]))\n",
    "\n",
    "  if pot == 0 and train_counter < train_target:\n",
    "    # a training candidate\n",
    "    if label in y_val or label in y_test:\n",
    "      # no thank you\n",
    "      continue\n",
    "      \n",
    "    # add noise?\n",
    "    if NOISE:\n",
    "      image += np.random.uniform(0, 0.05,(100,100))\n",
    "      \n",
    "    # safe to add to training\n",
    "    X_train[train_counter] = image\n",
    "    y_train[train_counter] = label\n",
    "    train_counter += 1\n",
    "    \n",
    "  elif pot == 1 and val_counter < val_target:\n",
    "    # a validation candidate\n",
    "    if label in y_train or label in y_test:\n",
    "      # no thank you\n",
    "      continue\n",
    "      \n",
    "    # add noise?\n",
    "    if NOISE:\n",
    "      image += np.random.uniform(0, 0.05,(100,100))\n",
    "      \n",
    "    # safe to add to validation\n",
    "    X_val[val_counter] = image\n",
    "    y_val[val_counter] = label\n",
    "    val_counter += 1\n",
    "  \n",
    "  elif pot == 2 and test_counter < test_target:\n",
    "    # a test candidate\n",
    "    if label in y_train or label in y_val:\n",
    "      # no thank you\n",
    "      continue\n",
    "      \n",
    "    # add noise?\n",
    "    if NOISE:\n",
    "      image += np.random.uniform(0, 0.05,(100,100))\n",
    "      \n",
    "    # safe to add to test\n",
    "    X_test[test_counter] = image\n",
    "    y_test[test_counter] = label\n",
    "    test_counter += 1\n",
    "  \n",
    "  \n",
    "  \n",
    "print 'Done', time.time()-t0, 'seconds (', all_counter, 'iterations)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage 4000.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_min = min(X_train.min(), X_val.min(), X_test.min())\n",
    "X_max = max(X_train.max(), X_val.max(), X_test.max())\n",
    "y_min = min(y_train.min(), y_val.min(), y_test.min())\n",
    "y_max = max(y_train.max(), y_val.max(), y_test.max())\n",
    "\n",
    "# scale in place\n",
    "X_train -= X_min\n",
    "X_train /= (X_max - X_min)\n",
    "X_val -= X_min\n",
    "X_val /= (X_max - X_min)\n",
    "X_test -= X_min\n",
    "X_test /= (X_max - X_min)\n",
    "y_train -= y_min\n",
    "y_train /= (y_max - y_min)\n",
    "y_val -= y_min\n",
    "y_val /= (y_max - y_min)\n",
    "y_test -= y_min\n",
    "y_test /= (y_max - y_min)\n",
    "\n",
    "# normalize to -.5 .. .5\n",
    "X_train -= .5\n",
    "X_val -= .5\n",
    "X_test -= .5\n",
    "\n",
    "print 'memory usage', (X_train.nbytes + X_val.nbytes + X_test.nbytes + y_train.nbytes + y_val.nbytes + y_test.nbytes) / 1000000., 'MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "classifier = models.Sequential()\n",
    "classifier.add(layers.Convolution2D(20, (5, 5), padding=\"same\", input_shape=(100, 100, 1)))\n",
    "classifier.add(layers.Activation(\"relu\"))\n",
    "classifier.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "classifier.add(layers.Dropout(0.2))\n",
    "classifier.add(layers.Convolution2D(50, (5, 5), padding=\"same\"))\n",
    "classifier.add(layers.Activation(\"relu\"))\n",
    "classifier.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "classifier.add(layers.Dropout(0.2))\n",
    "classifier.add(layers.Flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_shape = classifier.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#MLP = models.Sequential()\n",
    "MLP = classifier\n",
    "MLP.add(layers.Dense(256, activation='relu', input_dim=feature_shape))\n",
    "MLP.add(layers.Dropout(0.5))\n",
    "MLP.add(layers.Dense(1, activation='linear')) # REGRESSION\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "MLP.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse', 'mae']) # MSE for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 20000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0953 - mean_squared_error: 0.0953 - mean_absolute_error: 0.2680 - val_loss: 0.1078 - val_mean_squared_error: 0.1078 - val_mean_absolute_error: 0.2804\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0853 - mean_squared_error: 0.0853 - mean_absolute_error: 0.2564 - val_loss: 0.0850 - val_mean_squared_error: 0.0850 - val_mean_absolute_error: 0.2428\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0715 - mean_squared_error: 0.0715 - mean_absolute_error: 0.2348 - val_loss: 0.0578 - val_mean_squared_error: 0.0578 - val_mean_absolute_error: 0.1959\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0571 - mean_squared_error: 0.0571 - mean_absolute_error: 0.2083 - val_loss: 0.0450 - val_mean_squared_error: 0.0450 - val_mean_absolute_error: 0.1714\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0431 - mean_squared_error: 0.0431 - mean_absolute_error: 0.1772 - val_loss: 0.0282 - val_mean_squared_error: 0.0282 - val_mean_absolute_error: 0.1358\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - mean_absolute_error: 0.1464 - val_loss: 0.0167 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.1036\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - mean_absolute_error: 0.1216 - val_loss: 0.0106 - val_mean_squared_error: 0.0106 - val_mean_absolute_error: 0.0791\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - mean_absolute_error: 0.1087 - val_loss: 0.0074 - val_mean_squared_error: 0.0074 - val_mean_absolute_error: 0.0639\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - mean_absolute_error: 0.1017 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0555\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - mean_absolute_error: 0.0977 - val_loss: 0.0048 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0499\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - mean_absolute_error: 0.0937 - val_loss: 0.0043 - val_mean_squared_error: 0.0043 - val_mean_absolute_error: 0.0470\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0915 - val_loss: 0.0038 - val_mean_squared_error: 0.0038 - val_mean_absolute_error: 0.0447\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - mean_absolute_error: 0.0896 - val_loss: 0.0035 - val_mean_squared_error: 0.0035 - val_mean_absolute_error: 0.0435\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - mean_absolute_error: 0.0884 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0411\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0861 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0399\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0849 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0375\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0844 - val_loss: 0.0028 - val_mean_squared_error: 0.0028 - val_mean_absolute_error: 0.0377\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0831 - val_loss: 0.0028 - val_mean_squared_error: 0.0028 - val_mean_absolute_error: 0.0406\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - mean_absolute_error: 0.0823 - val_loss: 0.0027 - val_mean_squared_error: 0.0027 - val_mean_absolute_error: 0.0358\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - mean_absolute_error: 0.0813 - val_loss: 0.0025 - val_mean_squared_error: 0.0025 - val_mean_absolute_error: 0.0363\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - mean_absolute_error: 0.0804 - val_loss: 0.0025 - val_mean_squared_error: 0.0025 - val_mean_absolute_error: 0.0346\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0802 - val_loss: 0.0024 - val_mean_squared_error: 0.0024 - val_mean_absolute_error: 0.0341\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0792 - val_loss: 0.0023 - val_mean_squared_error: 0.0023 - val_mean_absolute_error: 0.0339\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0790 - val_loss: 0.0023 - val_mean_squared_error: 0.0023 - val_mean_absolute_error: 0.0347\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0783 - val_loss: 0.0022 - val_mean_squared_error: 0.0022 - val_mean_absolute_error: 0.0346\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0778 - val_loss: 0.0022 - val_mean_squared_error: 0.0022 - val_mean_absolute_error: 0.0337\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0776 - val_loss: 0.0021 - val_mean_squared_error: 0.0021 - val_mean_absolute_error: 0.0337\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - mean_absolute_error: 0.0769 - val_loss: 0.0021 - val_mean_squared_error: 0.0021 - val_mean_absolute_error: 0.0328\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0762 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0324\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - mean_absolute_error: 0.0759 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0337\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - mean_absolute_error: 0.0755 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0321\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0745 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0322\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0747 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0319\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0745 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0314\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - mean_absolute_error: 0.0742 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0736 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0317\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0732 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0311\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0729 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0318\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0725 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0314\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0721 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0303\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0721 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0311\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0717 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0315\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0717 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0305\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0718 - val_loss: 0.0018 - val_mean_squared_error: 0.0018 - val_mean_absolute_error: 0.0307\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0712 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0299\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0707 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0300\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0705 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0296\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0706 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0301\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0702 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0301\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0700 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0297\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0696 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0300\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0693 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0297\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0695 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0303\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0692 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0296\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0692 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0294\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0687 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0300\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0683 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0290\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0687 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0291\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0683 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0294\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0680 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0299\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0681 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0291\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0677 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0285\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0676 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0289\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0676 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0288\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0670 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0291\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0674 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0289\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - mean_absolute_error: 0.0667 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0285\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - mean_absolute_error: 0.0669 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0289\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0665 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0283\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0664 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0291\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0664 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0283\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0663 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0283\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0658 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0282\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0659 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0285\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0662 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0285\n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0657 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0284\n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0658 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0285\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0660 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0286\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0652 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0286\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0658 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0283\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0651 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0286\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0653 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0280\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0646 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0281\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0648 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0282\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0644 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0284\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0649 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0283\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0642 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0285\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0644 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0283\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0641 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0282\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0643 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0278\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0639 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0282\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0638 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0279\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0638 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0281\n",
      "Epoch 94/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0638 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0278\n",
      "Epoch 95/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0635 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0281\n",
      "Epoch 96/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0632 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0280\n",
      "Epoch 97/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0636 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0279\n",
      "Epoch 98/1000\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0632 - val_loss: 0.0015 - val_mean_squared_error: 0.0015 - val_mean_absolute_error: 0.0278\n",
      "Epoch 99/1000\n",
      "53184/60000 [=========================>....] - ETA: 6s - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0632"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')]\n",
    "\n",
    "history = MLP.fit(X_train.reshape(len(X_train), 100, 100, 1), \\\n",
    "                  y_train, \\\n",
    "                  epochs=1000, \\\n",
    "                  batch_size=32, \\\n",
    "                  validation_data=(X_val.reshape(len(X_val), 100, 100, 1), y_val),\n",
    "                  callbacks=callbacks,\n",
    "                  verbose=True)\n",
    "print 'Fitting done', time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = MLP.predict(X_test.reshape(len(X_test), 100, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "np.log2(sklearn.metrics.mean_absolute_error(y_pred*100, y_test*100)+.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22938162],\n",
       "       [ 0.14699593],\n",
       "       [ 0.6785295 ],\n",
       "       ..., \n",
       "       [ 0.71962476],\n",
       "       [ 0.86336124],\n",
       "       [ 0.2867682 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25842696,  0.14606741,  0.75280899, ...,  0.75280899,\n",
       "        0.86516851,  0.29213482], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8876698"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_absolute_error(y_pred*100, y_test*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
