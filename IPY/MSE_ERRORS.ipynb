{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ClevelandMcGill' from '../EXP/ClevelandMcGill/__init__.pyc'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import cPickle as pickle\n",
    "sys.path.append('../EXP/')\n",
    "import ClevelandMcGill as C\n",
    "from util import Util\n",
    "reload(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR2 = '/n/regal/pfister_lab/PERCEPTION/RESULTS_FROM_SCRATCH/'\n",
    "RESULTS_DIR = '/n/regal/pfister_lab/PERCEPTION/RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments = ['C.Figure1.position_common_scale', \\\n",
    "               'C.Figure1.position_non_aligned_scale', \\\n",
    "               'C.Figure1.length', \\\n",
    "               'C.Figure1.direction', \\\n",
    "               'C.Figure1.angle', \\\n",
    "               'C.Figure1.area', \\\n",
    "               'C.Figure1.volume', \\\n",
    "               'C.Figure1.curvature', \\\n",
    "               'C.Figure1.shading']\n",
    "all_labels = {'C.Figure1.position_common_scale': ['Position Y', '+ Position X', '+ Spotsize'], \\\n",
    "              'C.Figure1.position_non_aligned_scale': ['Position Y', '+ Position X', '+ Spotsize'],\\\n",
    "              'C.Figure1.length': ['Length', '+ Position Y', '+ Position X', '+ Width'], \\\n",
    "              'C.Figure1.direction': ['Direction', '+ Position Y', '+ Position X'], \\\n",
    "              'C.Figure1.angle': ['Angle', '+ Position Y', '+ Position X'], \\\n",
    "              'C.Figure1.area': ['Area', '+ Position Y', '+ Position X'], \\\n",
    "              'C.Figure1.volume': ['Volume', '+ Position Y', '+ Position X'], \\\n",
    "              'C.Figure1.curvature': ['Curvature', '+ Position Y', '+ Position X'], \\\n",
    "              'C.Figure1.shading': ['Shading', '+ Position Y', '+ Position X']\n",
    "              }\n",
    "\n",
    "presets = {\n",
    " 'C.Figure1.position_common_scale': 40, \\\n",
    " 'C.Figure1.position_non_aligned_scale': 10, \\\n",
    " 'C.Figure1.length': 35, \\\n",
    " 'C.Figure1.direction': 215, \\\n",
    " 'C.Figure1.angle': 60, \\\n",
    " 'C.Figure1.area': 20, \\\n",
    " 'C.Figure1.volume': 18, \\\n",
    " 'C.Figure1.curvature': 50, \\\n",
    " 'C.Figure1.shading': 80\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded C.Figure1.position_common_scale\n",
      "Loaded C.Figure1.position_non_aligned_scale\n",
      "Loaded C.Figure1.length\n",
      "Loaded C.Figure1.direction\n",
      "Loaded C.Figure1.angle\n",
      "Loaded C.Figure1.area\n",
      "Loaded C.Figure1.volume\n",
      "Loaded C.Figure1.curvature\n",
      "Loaded C.Figure1.shading\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for experiment in experiments:\n",
    "\n",
    "    e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "    datasets = sorted(os.listdir(e_dir))\n",
    "#     print datasets\n",
    "    results = [None]*4\n",
    "    \n",
    "    e_dir2 = os.path.join(RESULTS_DIR2, experiment)\n",
    "\n",
    "    classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "    for i,c in enumerate(classifiers):\n",
    "\n",
    "        results[i] = []\n",
    "        for d in datasets:\n",
    "            d_dir = os.path.join(e_dir, d)\n",
    "\n",
    "#             stats_files = ['01_noise.p', '02_noise.p', '03_noise.p', '04_noise.p']#glob.glob(os.path.join(d_dir, c)+'/*.p')\n",
    "            stats_files = glob.glob(os.path.join(d_dir, c)+'/*.p')\n",
    "#             print stats_files\n",
    "#             break\n",
    "            MLAEs = []\n",
    "\n",
    "            for s in stats_files:\n",
    "#                 stats_file = os.path.join(d_dir, c)+'/'+s\n",
    "                stats_file = s\n",
    "#                 print s\n",
    "                if os.path.exists(stats_file):\n",
    "                    with open(stats_file, 'r') as f:\n",
    "                        stats = pickle.load(f)\n",
    "                    MSE = sklearn.metrics.mean_squared_error(stats['y_test'], stats['y_pred'])\n",
    "                    MLAEs.append(MSE)\n",
    "\n",
    "            results[i].append(MLAEs)\n",
    "            \n",
    "            \n",
    "    results2 = [None]*2\n",
    "    classifiers2 = ['VGG19', 'XCEPTION']\n",
    "    for i,c in enumerate(classifiers2):\n",
    "\n",
    "        results2[i] = []\n",
    "        for d in datasets:\n",
    "            d_dir = os.path.join(e_dir2, d)\n",
    "\n",
    "#             stats_files = ['01_noise.p', '02_noise.p', '03_noise.p', '04_noise.p']#glob.glob(os.path.join(d_dir, c)+'/*.p')\n",
    "            stats_files = glob.glob(os.path.join(d_dir, c)+'/*.p')\n",
    "#             print stats_files\n",
    "#             break\n",
    "            MLAEs = []\n",
    "\n",
    "            for s in stats_files:\n",
    "#                 stats_file = os.path.join(d_dir, c)+'/'+s\n",
    "                stats_file = s\n",
    "#                 print s\n",
    "                if os.path.exists(stats_file):\n",
    "                    with open(stats_file, 'r') as f:\n",
    "                        stats = pickle.load(f)\n",
    "                    \n",
    "                    MSE = sklearn.metrics.mean_squared_error(stats['y_test'], stats['y_pred'])\n",
    "                    MLAEs.append(MSE)\n",
    "\n",
    "            results2[i].append(MLAEs)\n",
    "            \n",
    "            \n",
    "    print 'Loaded', experiment\n",
    "            \n",
    "    all_results[experiment] = results + results2\n",
    "            \n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C.Figure1.position_common_scale\n",
      "C.Figure1.position_non_aligned_scale\n",
      "C.Figure1.length\n",
      "C.Figure1.direction\n",
      "C.Figure1.angle\n",
      "C.Figure1.area\n",
      "C.Figure1.volume\n",
      "C.Figure1.curvature\n",
      "C.Figure1.shading\n"
     ]
    }
   ],
   "source": [
    "for z,experiment in enumerate(experiments):\n",
    "#     print classifiers3\n",
    "    print experiment\n",
    "#     print 'b4', all_results_fresh[experiment][3]\n",
    "    all_results[experiment][3], all_results[experiment][4] =  \\\n",
    "        all_results[experiment][4], all_results[experiment][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & MLP & LeNet & VGG19 * & VGG19 & XCEPTION * & XCEPTION \\\\\n",
      "\\emph{C.Figure1.position_common_scale} & $0.03794 \\pm 0.01436 $ & $0.00106 \\pm 0.00028 $ & $0.00079 \\pm 0.00027 $ & $0.00014 \\pm 9e-05 $ & $0.0017 \\pm 0.00036 $ & $0.00074 \\pm 0.00034 $ &  \\\\ \n",
      "\\emph{C.Figure1.position_non_aligned_scale} & $0.02974 \\pm 0.00912 $ & $0.00097 \\pm 0.00043 $ & $0.00081 \\pm 0.00016 $ & $0.00021 \\pm 0.00013 $ & $0.00183 \\pm 0.00047 $ & $0.0006 \\pm 6e-05 $ &  \\\\ \n",
      "\\emph{C.Figure1.length} & $0.00267 \\pm 0.00053 $ & $0.01044 \\pm 0.00301 $ & $0.00046 \\pm 5e-05 $ & $0.0001 \\pm 2e-05 $ & $0.00142 \\pm 0.00021 $ & $0.00066 \\pm 0.0001 $ &  \\\\ \n",
      "\\emph{C.Figure1.direction} & $0.08359 \\pm 0.00645 $ & $0.01409 \\pm 0.00575 $ & $0.01014 \\pm 0.00212 $ & $0.00121 \\pm 0.0009 $ & $0.02342 \\pm 0.00556 $ & $0.00247 \\pm 0.00159 $ &  \\\\ \n",
      "\\emph{C.Figure1.angle} & $0.08092 \\pm 0.00953 $ & $0.01859 \\pm 0.00611 $ & $0.00415 \\pm 0.00087 $ & $0.00053 \\pm 6e-05 $ & $0.00607 \\pm 0.00064 $ & $0.00158 \\pm 0.00019 $ &  \\\\ \n",
      "\\emph{C.Figure1.area} & $0.00256 \\pm 0.00074 $ & $0.00383 \\pm 0.00171 $ & $0.00031 \\pm 0.00016 $ & $0.0001 \\pm 4e-05 $ & $0.00047 \\pm 0.00013 $ & $0.13955 \\pm 0.2288 $ &  \\\\ \n",
      "\\emph{C.Figure1.volume} & $0.00593 \\pm 0.00382 $ & $0.00405 \\pm 0.00567 $ & $0.001 \\pm 0.00067 $ & $0.00084 \\pm 0.00065 $ & $0.00339 \\pm 0.00218 $ & $0.00346 \\pm 0.0005 $ &  \\\\ \n",
      "\\emph{C.Figure1.curvature} & $0.00343 \\pm 0.00076 $ & $0.00065 \\pm 0.00015 $ & $0.00024 \\pm 3e-05 $ & $6e-05 \\pm 1e-05 $ & $0.00047 \\pm 0.0001 $ & $0.00254 \\pm 0.00108 $ &  \\\\ \n",
      "\\emph{C.Figure1.shading} & $0.01861 \\pm 0.00811 $ & $0.00448 \\pm 0.00205 $ & $0.00078 \\pm 0.00067 $ & $0.00032 \\pm 0.00021 $ & $0.00303 \\pm 0.00138 $ & $0.00657 \\pm 0.00473 $ &  \\\\ \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'VGG19', 'XCEPTION *', 'XCEPTION']\n",
    "print ' & ' + ' & '.join(classifiers) + ' \\\\\\\\'\n",
    "\n",
    "for x,e in enumerate(experiments):\n",
    "    \n",
    "    line = '\\emph{' +e + '} & '\n",
    "    \n",
    "    for i,c in enumerate(classifiers):\n",
    "    \n",
    "        \n",
    "        mse = all_results[e][i][-1]\n",
    "#         print 'a', mse\n",
    "        mse_mean = np.mean(mse)\n",
    "        mse_std = np.std(mse)\n",
    "#         print mse_mean, mse_std\n",
    "        line += '$' + str(np.round(mse_mean,5)) + ' \\pm ' + str(np.round(mse_std,5)) +' $ & '\n",
    "        \n",
    "    print line + ' \\\\\\\\ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/n/regal/pfister_lab/PERCEPTION/RESULTS/'\n",
    "RESULTS_DIR2 = '/n/regal/pfister_lab/PERCEPTION/RESULTS_FROM_SCRATCH/'\n",
    "experiment = 'C.Figure3.data_to_barchart'\n",
    "e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "datasets = sorted(os.listdir(e_dir))\n",
    "\n",
    "bar_stats = [None]*6\n",
    "\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "    \n",
    "    bar_stats[i] = []\n",
    "    c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*_noise.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    bar_stats[i].append(stats_per_c)\n",
    "            \n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])\n",
    "classifiers2 = ['VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers2):\n",
    "    \n",
    "    bar_stats[i+4] = []\n",
    "    c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*_noise.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    bar_stats[i+4].append(stats_per_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 'C.Figure3.data_to_piechart'\n",
    "e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "datasets = sorted(os.listdir(e_dir))\n",
    "\n",
    "pie_stats = [None]*6\n",
    "\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "    \n",
    "    pie_stats[i] = []\n",
    "    c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*_noise.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    pie_stats[i].append(stats_per_c)\n",
    "            \n",
    "classifiers2 = ['VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers2):\n",
    "    \n",
    "    pie_stats[i+4] = []\n",
    "    c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*_noise.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    pie_stats[i+4].append(stats_per_c)\n",
    "        \n",
    "        \n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'Xception *', 'VGG19', 'Xception']\n",
    "\n",
    "bar_data = [None]*6\n",
    "pie_data = [None]*6\n",
    "\n",
    "for i, c in enumerate(classifiers):\n",
    "\n",
    "    bar_mlae_s = []\n",
    "    pie_mlae_s = []\n",
    "    \n",
    "    for sample in range(len(bar_stats[i][0])):\n",
    "\n",
    "        # grab sample from both\n",
    "#         bar_mlae = bar_stats[i][0][sample]['MSE']\n",
    "        bar_MSE = sklearn.metrics.mean_squared_error(bar_stats[i][0][sample]['y_test'], bar_stats[i][0][sample]['y_pred'])\n",
    "        pie_MSE = sklearn.metrics.mean_squared_error(pie_stats[i][0][sample]['y_test'], pie_stats[i][0][sample]['y_pred'])\n",
    "\n",
    "#         print i, sample, bar_mlae, pie_mlae\n",
    "        bar_mlae_s.append(bar_MSE)\n",
    "        pie_mlae_s.append(pie_MSE)\n",
    "        \n",
    "    bar_data[i] = bar_mlae_s\n",
    "    pie_data[i] = pie_mlae_s\n",
    "    \n",
    "# swap vgg19 and xception *\n",
    "pie_data[3], pie_data[4] = pie_data[4], pie_data[3]\n",
    "bar_data[3], bar_data[4] = bar_data[4], bar_data[3]\n",
    "\n",
    "all_data = [pie_data, bar_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & MLP & LeNet & VGG19 * & VGG19 & XCEPTION * & XCEPTION \\\\\n",
      "\\emph{PIE CHART} & $0.04725 \\pm 0.00177 $ & $0.02429 \\pm 0.0007 $ & $0.02492 \\pm 0.00143 $ & $0.00095 \\pm 0.00018 $ & $0.01371 \\pm 0.00078 $ & $0.0026 \\pm 0.00037 $ &  \\\\ \n",
      "\\emph{BAR CHART} & $0.00629 \\pm 0.00051 $ & $0.00322 \\pm 0.00029 $ & $0.00723 \\pm 0.00107 $ & $0.00076 \\pm 0.00012 $ & $0.00465 \\pm 0.0002 $ & $0.00109 \\pm 0.0001 $ &  \\\\ \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'VGG19', 'XCEPTION *', 'XCEPTION']\n",
    "print ' & ' + ' & '.join(classifiers) + ' \\\\\\\\'\n",
    "experiments = ['PIE CHART', 'BAR CHART']\n",
    "for x,e in enumerate(all_data):\n",
    "    \n",
    "    line = '\\emph{' + experiments[x] + '} & '\n",
    "    \n",
    "    for i,c in enumerate(classifiers):\n",
    "    \n",
    "        \n",
    "        mse = all_data[x][i]\n",
    "#         print 'a', mse\n",
    "        mse_mean = np.mean(mse)\n",
    "        mse_std = np.std(mse)\n",
    "#         print mse_mean, mse_std\n",
    "        line += '$' + str(np.round(mse_mean,5)) + ' \\pm ' + str(np.round(mse_std,5)) +' $ & '\n",
    "        \n",
    "    print line + ' \\\\\\\\ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/n/regal/pfister_lab/PERCEPTION/RESULTS/'\n",
    "RESULTS_DIR2 = '/n/regal/pfister_lab/PERCEPTION/RESULTS_FROM_SCRATCH//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stats = [None]*6\n",
    "\n",
    "for a in range(1,6):\n",
    "\n",
    "    experiment = 'C.Figure4.data_to_type'+str(a)\n",
    "    e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "    e2_dir  = os.path.join(RESULTS_DIR2, experiment)\n",
    "\n",
    "    stats = [None]*6\n",
    "\n",
    "    classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "    for i,c in enumerate(classifiers):\n",
    "\n",
    "        stats[i] = []\n",
    "        c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "        stats_files = glob.glob(c_dir+'/*.p')\n",
    "        stats_per_c = []\n",
    "    #     print stats_files\n",
    "\n",
    "        for s in stats_files:\n",
    "\n",
    "            with open(s, 'r') as f:\n",
    "                stats_from_file = pickle.load(f)\n",
    "            stats_per_c.append(stats_from_file)\n",
    "    #         print stats['time']\n",
    "\n",
    "        stats[i].append(stats_per_c)\n",
    "        \n",
    "    classifiers = ['VGG19', 'XCEPTION']\n",
    "    for i,c in enumerate(classifiers):\n",
    "\n",
    "        stats[i+4] = []\n",
    "        c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "        stats_files = glob.glob(c_dir+'/*.p')\n",
    "        stats_per_c = []\n",
    "    #     print stats_files\n",
    "\n",
    "        for s in stats_files:\n",
    "\n",
    "            with open(s, 'r') as f:\n",
    "                stats_from_file = pickle.load(f)\n",
    "            stats_per_c.append(stats_from_file)\n",
    "    #         print stats['time']\n",
    "\n",
    "        stats[i+4].append(stats_per_c)\n",
    "        \n",
    "#     print stats\n",
    "    all_stats[a-1] = stats\n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])\n",
    "\n",
    "\n",
    "experiment = 'C.Figure4.multi'\n",
    "e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "\n",
    "stats = [None]*6\n",
    "\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION', 'VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "\n",
    "    stats[i] = []\n",
    "    if i < 4:\n",
    "        c_dir = os.path.join(e_dir, c)\n",
    "    else:\n",
    "        c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "\n",
    "        with open(s, 'r') as f:\n",
    "            stats_from_file = pickle.load(f)\n",
    "        stats_per_c.append(stats_from_file)\n",
    "#         print stats['time']\n",
    "\n",
    "    stats[i].append(stats_per_c)\n",
    "#     print stats\n",
    "all_stats[5] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 6 1\n",
      "0 2 6 1\n",
      "0 3 6 1\n",
      "0 4 6 1\n",
      "0 5 6 1\n",
      "0 6 6 1\n",
      "1 1 6 1\n",
      "1 2 6 1\n",
      "1 3 6 1\n",
      "1 4 6 1\n",
      "1 5 6 1\n",
      "1 6 6 1\n",
      "2 1 6 1\n",
      "2 2 6 1\n",
      "2 3 6 1\n",
      "2 4 6 1\n",
      "2 5 6 1\n",
      "2 6 6 1\n",
      "3 1 6 1\n",
      "3 2 6 1\n",
      "3 3 6 1\n",
      "3 4 6 1\n",
      "3 5 6 1\n",
      "3 6 6 1\n",
      "4 1 6 1\n",
      "4 2 6 1\n",
      "4 3 6 1\n",
      "4 4 6 1\n",
      "4 5 6 1\n",
      "4 6 6 1\n",
      "5 1 6 1\n",
      "5 2 6 1\n",
      "5 3 6 1\n",
      "5 4 6 1\n",
      "5 5 6 1\n",
      "5 6 6 1\n"
     ]
    }
   ],
   "source": [
    "all_data = [None]*6\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'Xception', 'VGG19', 'Xception']\n",
    "for i, c in enumerate(classifiers):\n",
    "\n",
    "    mlae_for_c = []\n",
    "    \n",
    "    for type_ in range(1,7):\n",
    "        \n",
    "        mlae_for_type = []\n",
    "        print i, type_, len(all_stats[type_-1]), len(all_stats[type_-1][i])\n",
    "        for sample in range(len(all_stats[type_-1][i][0])):\n",
    "\n",
    "            mse_for_sample = sklearn.metrics.mean_squared_error(all_stats[type_-1][i][0][sample]['y_test'], all_stats[type_-1][i][0][sample]['y_pred'])\n",
    "\n",
    "            mlae_for_type.append(mse_for_sample)\n",
    "    \n",
    "        mlae_for_c.append(mlae_for_type)\n",
    "        \n",
    "    all_data[i] = mlae_for_c\n",
    "    \n",
    "\n",
    "all_data[3], all_data[4] = all_data[4], all_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & MLP & LeNet & VGG19 * & VGG19 & XCEPTION * & XCEPTION \\\\\n",
      "\\emph{TYPE 1} & $0.03561 \\pm 0.01403 $ & $0.13262 \\pm 0.07927 $ & $0.04563 \\pm 0.02225 $ & $0.04259 \\pm 0.01621 $ & $0.07448 \\pm 0.041 $ & $0.10515 \\pm 0.0437 $ &  \\\\ \n",
      "\\emph{TYPE 2} & $0.0427 \\pm 0.04115 $ & $0.07342 \\pm 0.042 $ & $0.12256 \\pm 0.06932 $ & $0.03976 \\pm 0.02488 $ & $0.04624 \\pm 0.02606 $ & $0.08235 \\pm 0.02587 $ &  \\\\ \n",
      "\\emph{TYPE 3} & $0.06055 \\pm 0.02853 $ & $0.04998 \\pm 0.08381 $ & $0.09711 \\pm 0.0405 $ & $0.02746 \\pm 0.01733 $ & $0.03701 \\pm 0.01777 $ & $0.08443 \\pm 0.04828 $ &  \\\\ \n",
      "\\emph{TYPE 4} & $0.07275 \\pm 0.0309 $ & $0.05433 \\pm 0.04709 $ & $0.03922 \\pm 0.02143 $ & $0.03065 \\pm 0.02038 $ & $0.05543 \\pm 0.06636 $ & $0.06119 \\pm 0.06254 $ &  \\\\ \n",
      "\\emph{TYPE 5} & $0.06728 \\pm 0.02543 $ & $0.03583 \\pm 0.02154 $ & $0.12193 \\pm 0.05223 $ & $0.04314 \\pm 0.03622 $ & $0.04574 \\pm 0.01683 $ & $0.07167 \\pm 0.02072 $ &  \\\\ \n",
      "\\emph{MULTI} & $0.02624 \\pm 0.01729 $ & $0.04419 \\pm 0.02724 $ & $0.07631 \\pm 0.02532 $ & $0.01756 \\pm 0.00931 $ & $0.0385 \\pm 0.0271 $ & $0.08365 \\pm 0.02061 $ &  \\\\ \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'VGG19', 'XCEPTION *', 'XCEPTION']\n",
    "print ' & ' + ' & '.join(classifiers) + ' \\\\\\\\'\n",
    "experiments = ['TYPE 1', 'TYPE 2', 'TYPE 3', 'TYPE 4', 'TYPE 5', 'MULTI']\n",
    "for x,e in enumerate(all_data):\n",
    "    \n",
    "    line = '\\emph{' + experiments[x] + '} & '\n",
    "    \n",
    "    for i,c in enumerate(classifiers):\n",
    "    \n",
    "        \n",
    "        mse = all_data[x][i]\n",
    "#         print 'a', mse\n",
    "        mse_mean = np.mean(mse)\n",
    "        mse_std = np.std(mse)\n",
    "#         print mse_mean, mse_std\n",
    "        line += '$' + str(np.round(mse_mean,5)) + ' \\pm ' + str(np.round(mse_std,5)) +' $ & '\n",
    "        \n",
    "    print line + ' \\\\\\\\ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/n/regal/pfister_lab/PERCEPTION/RESULTS/'\n",
    "RESULTS_DIR2 = '/n/regal/pfister_lab/PERCEPTION/RESULTS_FROM_SCRATCH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 'C.Figure12.data_to_bars'\n",
    "e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "datasets = sorted(os.listdir(e_dir))\n",
    "\n",
    "bar_stats = [None]*6\n",
    "\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "    \n",
    "    bar_stats[i] = []\n",
    "    c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    bar_stats[i].append(stats_per_c)\n",
    "    \n",
    "classifiers2 = ['VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers2):\n",
    "    \n",
    "    bar_stats[i+4] = []\n",
    "    c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    bar_stats[i+4].append(stats_per_c)\n",
    "            \n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 'C.Figure12.data_to_framed_rectangles'\n",
    "e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "datasets = sorted(os.listdir(e_dir))\n",
    "\n",
    "rect_stats = [None]*6\n",
    "\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "    \n",
    "    rect_stats[i] = []\n",
    "    c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    rect_stats[i].append(stats_per_c)\n",
    "    \n",
    "classifiers = ['VGG19', 'XCEPTION']\n",
    "for i,c in enumerate(classifiers):\n",
    "    \n",
    "    rect_stats[i+4] = []\n",
    "    c_dir = os.path.join(e2_dir, c)\n",
    "\n",
    "    stats_files = glob.glob(c_dir+'/*.p')\n",
    "    stats_per_c = []\n",
    "#     print stats_files\n",
    "\n",
    "    for s in stats_files:\n",
    "        \n",
    "        with open(s, 'r') as f:\n",
    "            stats = pickle.load(f)\n",
    "        stats_per_c.append(stats)\n",
    "#         print stats['time']\n",
    "\n",
    "    rect_stats[i+4].append(stats_per_c)\n",
    "            \n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bar_data = [None]*6\n",
    "rect_data = [None]*6\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'Xception *', 'VGG19', 'Xception']\n",
    "for i, c in enumerate(classifiers):\n",
    "\n",
    "    bar_mlae_s = []\n",
    "    rect_mlae_s = []\n",
    "    \n",
    "    for sample in range(len(bar_stats[i][0])):\n",
    "\n",
    "        # grab sample from both\n",
    "        bar_mse = sklearn.metrics.mean_squared_error(bar_stats[i][0][sample]['y_test'], bar_stats[i][0][sample]['y_pred'])\n",
    "\n",
    "        rect_mse = sklearn.metrics.mean_squared_error(rect_stats[i][0][sample]['y_test'], rect_stats[i][0][sample]['y_pred'])\n",
    "\n",
    "#         print i, sample, bar_mlae, pie_mlae\n",
    "        bar_mlae_s.append(bar_mse)\n",
    "        rect_mlae_s.append(rect_mse)\n",
    "        \n",
    "    bar_data[i] = bar_mlae_s\n",
    "    rect_data[i] = rect_mlae_s\n",
    "    \n",
    "# swap vgg19 and xception *\n",
    "rect_data[3], rect_data[4] = rect_data[4], rect_data[3]\n",
    "bar_data[3], bar_data[4] = bar_data[4], bar_data[3]\n",
    "    \n",
    "all_data = [rect_data, bar_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & MLP & LeNet & VGG19 * & VGG19 & XCEPTION * & XCEPTION \\\\\n",
      "\\emph{FRAMED RECTANGLES} & $0.00065 \\pm 0.00012 $ & $0.01343 \\pm 0.00484 $ & $0.00156 \\pm 0.00029 $ & $0.00032 \\pm 0.00011 $ & $0.00437 \\pm 0.00069 $ & $0.00155 \\pm 0.00062 $ &  \\\\ \n",
      "\\emph{BARS} & $0.0006 \\pm 0.00012 $ & $0.00553 \\pm 0.00196 $ & $0.00173 \\pm 0.00037 $ & $0.00043 \\pm 0.00024 $ & $0.00531 \\pm 0.00073 $ & $0.00145 \\pm 0.00053 $ &  \\\\ \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'VGG19', 'XCEPTION *', 'XCEPTION']\n",
    "print ' & ' + ' & '.join(classifiers) + ' \\\\\\\\'\n",
    "experiments = ['FRAMED RECTANGLES', 'BARS']\n",
    "for x,e in enumerate(all_data):\n",
    "    \n",
    "    line = '\\emph{' + experiments[x] + '} & '\n",
    "    \n",
    "    for i,c in enumerate(classifiers):\n",
    "    \n",
    "        \n",
    "        mse = all_data[x][i]\n",
    "#         print 'a', mse\n",
    "        mse_mean = np.mean(mse)\n",
    "        mse_std = np.std(mse)\n",
    "#         print mse_mean, mse_std\n",
    "        line += '$' + str(np.round(mse_mean,5)) + ' \\pm ' + str(np.round(mse_std,5)) +' $ & '\n",
    "        \n",
    "    print line + ' \\\\\\\\ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/n/regal/pfister_lab/PERCEPTION/RESULTS/'\n",
    "RESULTS_DIR2 = '/n/regal/pfister_lab/PERCEPTION/RESULTS_FROM_SCRATCH//'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stats = [None]*3\n",
    "\n",
    "for a,c_base in enumerate(['10','100','1000']):\n",
    "\n",
    "    experiment = 'C.Weber.base'+c_base\n",
    "    e_dir = os.path.join(RESULTS_DIR, experiment)\n",
    "    e2_dir = os.path.join(RESULTS_DIR2, experiment)\n",
    "    datasets = sorted(os.listdir(e_dir))\n",
    "\n",
    "    stats = [None]*6\n",
    "\n",
    "    classifiers = ['MLP', 'LeNet', 'VGG19', 'XCEPTION', 'VGG19', 'XCEPTION']\n",
    "    for i,c in enumerate(classifiers):\n",
    "\n",
    "        stats[i] = []\n",
    "        if i >3:\n",
    "            c_dir = os.path.join(e2_dir, c)\n",
    "        else:\n",
    "            c_dir = os.path.join(e_dir, c)\n",
    "\n",
    "        stats_files = glob.glob(c_dir+'/*_noise.p')\n",
    "        stats_per_c = []\n",
    "#         print stats_files\n",
    "\n",
    "        for s in stats_files:\n",
    "        \n",
    "            with open(s, 'r') as f:\n",
    "                stats_from_file = pickle.load(f)\n",
    "            stats_per_c.append(stats_from_file)\n",
    "    #         print stats['time']\n",
    "\n",
    "        stats[i].append(stats_per_c)\n",
    "#     print stats\n",
    "    all_stats[a-1] = stats\n",
    "#         print d, c, np.mean([stats1['MLAE'], stats2['MLAE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = [None]*6\n",
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'Xception *', 'VGG19', 'Xception']\n",
    "for i, c in enumerate(classifiers):\n",
    "\n",
    "    mlae_for_c = []\n",
    "    \n",
    "    for a,c_base in enumerate(['10','100','1000']):\n",
    "        \n",
    "        mlae_for_type = []\n",
    "        \n",
    "        for sample in range(len(all_stats[a][i][0])):\n",
    "\n",
    "#             mlae_for_sample = all_stats[a][i][0][sample]['MLAE']\n",
    "            mse_for_sample = sklearn.metrics.mean_squared_error(all_stats[a][i][0][sample]['y_test'], all_stats[a][i][0][sample]['y_pred'])\n",
    "\n",
    "            mlae_for_type.append(mse_for_sample)\n",
    "    \n",
    "        mlae_for_c.append(mlae_for_type)\n",
    "        \n",
    "    all_data[i] = mlae_for_c\n",
    "    \n",
    "all_data[3], all_data[4] = all_data[4], all_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & MLP & LeNet & VGG19 * & VGG19 & XCEPTION * & XCEPTION \\\\\n",
      "\\emph{WEBER 10} & $0.10126 \\pm 0.00062 $ & $0.13759 \\pm 0.03183 $ & $0.09031 \\pm 0.0013 $ & $0.00899 \\pm 0.0015 $ & $0.09354 \\pm 0.00078 $ & $0.0683 \\pm 0.00207 $ &  \\\\ \n",
      "\\emph{WEBER 100} & $0.1025 \\pm 0.00057 $ & $0.10259 \\pm 0.00065 $ & $0.10202 \\pm 0.00038 $ & $0.09835 \\pm 0.00267 $ & $0.10174 \\pm 0.00034 $ & $0.10818 \\pm 0.01003 $ &  \\\\ \n",
      "\\emph{WEBER 1000} & $0.09946 \\pm 0.00095 $ & $0.03436 \\pm 0.01137 $ & $0.01477 \\pm 0.00059 $ & $0.00076 \\pm 8e-05 $ & $0.0261 \\pm 0.00026 $ & $0.01041 \\pm 0.00258 $ &  \\\\ \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['MLP', 'LeNet', 'VGG19 *', 'VGG19', 'XCEPTION *', 'XCEPTION']\n",
    "print ' & ' + ' & '.join(classifiers) + ' \\\\\\\\'\n",
    "experiments = ['WEBER 10', 'WEBER 100', 'WEBER 1000']\n",
    "\n",
    "\n",
    "rows = 3\n",
    "for row in range(rows):\n",
    "    \n",
    "    line = '\\emph{' + experiments[row] + '} & '\n",
    "    \n",
    "    for i, c in enumerate(classifiers):\n",
    "    \n",
    "        \n",
    "        mse = all_data[i][row]\n",
    "#         print 'a', mse\n",
    "        mse_mean = np.mean(mse)\n",
    "        mse_std = np.std(mse)\n",
    "#         print mse_mean, mse_std\n",
    "        line += '$' + str(np.round(mse_mean,5)) + ' \\pm ' + str(np.round(mse_std,5)) +' $ & '\n",
    "        \n",
    "    print line + ' \\\\\\\\ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
